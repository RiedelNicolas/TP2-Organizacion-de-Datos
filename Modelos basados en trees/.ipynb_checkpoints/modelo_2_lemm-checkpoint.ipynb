{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se importan las bibliotecas necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import pickle\n",
    "import nltk\n",
    "import spacy\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se lee el .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7613 non-null   int64 \n",
      " 1   keyword   7552 non-null   object\n",
      " 2   location  5080 non-null   object\n",
      " 3   text      7613 non-null   object\n",
      " 4   target    7613 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('../csv/train.csv')\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_with_target_error = [328,443,513,2619,3640,3900,4342,5781,6552,6554,6570,6701,6702,6729,6861,7226]\n",
    "train.loc[train['id'].isin(ids_with_target_error),'target'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3263 entries, 0 to 3262\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        3263 non-null   int64 \n",
      " 1   keyword   3237 non-null   object\n",
      " 2   location  2158 non-null   object\n",
      " 3   text      3263 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 102.1+ KB\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('../csv/test.csv')\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se leen las abreviaturas \n",
    "file = open('../abreviaturas.pkl','rb')\n",
    "abbreviations = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se cargan los embeddings pre-entrenados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#descargar de aca https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz, pesa 1.5gb\n",
    "EMBEDDING_FILE = '../GoogleNews-vectors-negative300.bin.gz'\n",
    "word2vec = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elaboración del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este modelo se aplicará NLP para el procesamiento de los tweets y se utilizarán distintos árboles de decisión para realizar las predicciones:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparación del set de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_embedding = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Devuelve lista de tweets con abreviaturas expandidas\n",
    "def expand_abbreviations(sentences):\n",
    "    expanded_sentences = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        expanded_sentence = []\n",
    "        \n",
    "        for word in sentence:\n",
    "            if word in abbreviations:\n",
    "                word = word.replace(word,abbreviations[word])\n",
    "            expanded_sentence.append(word)\n",
    "            \n",
    "        tokenized = nltk.word_tokenize(\" \".join(expanded_sentence))\n",
    "        expanded_sentences.append(tokenized)\n",
    "        \n",
    "    return expanded_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Devuelve los tweets en minuscula eliminando simbolos y numeros\n",
    "def remove_symbols_and_numbers(sentences):\n",
    "    clean_sentences = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        clean_sentence = []\n",
    "    \n",
    "        for word in sentence:\n",
    "            clean_word = re.sub('[^a-zA-Z]',' ', word)\n",
    "            if(clean_word != ' '):\n",
    "                clean_sentence.append(clean_word.lower())\n",
    "                \n",
    "        tokenized = nltk.word_tokenize(\" \".join(clean_sentence))\n",
    "        clean_sentences.append(tokenized)\n",
    "\n",
    "    return clean_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(sentences):\n",
    "    clean_sentences = []\n",
    "    for sentence in words:\n",
    "        clean_sentence = []\n",
    "        for word in sentence:\n",
    "            if word not in STOPWORDS:\n",
    "                clean_sentence.append(word)\n",
    "        clean_sentences.append(clean_sentence)\n",
    "    return clean_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARA QUE CORRA ESTA FUNCION HAY QUE PONER EN CONSOLA:\n",
    "# pip install spacy\n",
    "# spacy download en\n",
    "# Devuelve los tweets lematizados\n",
    "def lemmatize_tweets(sentences):\n",
    "    nlp = spacy.load('en')\n",
    "    lemmatized = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        sentence = ' '.join(sentence)\n",
    "        doc = nlp(sentence)\n",
    "        lemmatized.append([token.lemma_ for token in doc])\n",
    "    \n",
    "    return lemmatized    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Devuelve una lista de tweets dejando solo letras y lematizando las palabras\n",
    "def clean_text(df):\n",
    "    \n",
    "    words = df['text'].str.split()\n",
    "    words = remove_symbols_and_numbers(words)\n",
    "    words = expand_abbreviations(words)\n",
    "    words = remove_stopwords(words)\n",
    "    \n",
    "    return lemmatize_tweets(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweets_embeddings(df):\n",
    "\n",
    "    embeddings = np.zeros((len(df.index),long_embedding), dtype='float32') \n",
    "    normalized_embeddings = np.zeros((len(df.index),long_embedding),dtype='float32')\n",
    "\n",
    "    contador = 0\n",
    "    for tweet in df['clean_text']:\n",
    "        cant_palabras = 0\n",
    "        embedded_tweet = np.zeros((long_embedding,), dtype='float32')\n",
    "\n",
    "        for word in tweet:\n",
    "            if word in word2vec.vocab:\n",
    "                embedded_tweet = np.add(word2vec[word],embedded_tweet)\n",
    "                cant_palabras += 1     \n",
    "\n",
    "        embeddings[contador] = embedded_tweet\n",
    "\n",
    "        if cant_palabras!=0:\n",
    "            normalized_embeddings[contador] = np.divide(embedded_tweet,cant_palabras)\n",
    "        else:\n",
    "            normalized_embeddings[contador] = embedded_tweet\n",
    "\n",
    "        contador += 1    \n",
    "        \n",
    "    return embeddings, normalized_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Devuelve un dataframe con todos los features considerados para el modelo\n",
    "def generate_embeddings(df):\n",
    "    \n",
    "    df['clean_text'] = clean_text(df)\n",
    "    df.drop(columns=['keyword','location','text'], inplace=True)\n",
    "    df.set_index('id', inplace=True)\n",
    "    \n",
    "    return tweets_embeddings(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_train, normalized_embeddings_train = generate_embeddings(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embedding_file = open(\"../train_embedding_file_w2v.txt\", \"w\")\n",
    "\n",
    "for i in embeddings_train:\n",
    "    np.savetxt(train_embedding_file, i)\n",
    "\n",
    "train_embedding_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embedding_file = open(\"../train_embedding_file_w2v(norm).txt\", \"w\")\n",
    "\n",
    "for i in normalized_embeddings_train:\n",
    "    np.savetxt(train_embedding_file, i)\n",
    "\n",
    "train_embedding_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_test, normalized_embeddings_test = generate_embeddings(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embedding_file = open(\"../test_embedding_file_w2v.txt\", \"w\")\n",
    "\n",
    "for i in embeddings_test:\n",
    "    np.savetxt(test_embedding_file, i)\n",
    "\n",
    "test_embedding_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embedding_file = open(\"../test_embedding_file_w2v(norm).txt\", \"w\")\n",
    "\n",
    "for i in normalized_embeddings_test:\n",
    "    np.savetxt(test_embedding_file, i)\n",
    "\n",
    "test_embedding_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 300)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_train = np.loadtxt(\"../train_embedding_file_w2v.txt\").reshape(len(train.index),long_embedding)\n",
    "embeddings_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 300)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_embeddings_train = np.loadtxt(\"../train_embedding_file_w2v(norm).txt\").reshape(len(train.index),long_embedding)\n",
    "normalized_embeddings_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3263, 300)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_test = np.loadtxt(\"../test_embedding_file_w2v.txt\").reshape(len(test.index),long_embedding)\n",
    "embeddings_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3263, 300)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_embeddings_test = np.loadtxt(\"../test_embedding_file_w2v(norm).txt\").reshape(len(test.index),long_embedding)\n",
    "normalized_embeddings_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento del set de datos considerando sólo 'embeddings'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = normalized_embeddings_train, train.iloc[:,4].to_frame()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.7834645669291339\n",
      "Precision Score : 0.8074074074074075\n",
      "Recall Score : 0.6586102719033232\n",
      "F1 Score : 0.7254575707154741\n"
     ]
    }
   ],
   "source": [
    "xg_reg = xgb.XGBRegressor(objective ='binary:logistic', \n",
    "                colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 10, alpha = 15, n_estimators = 5)\n",
    "\n",
    "xg_reg.fit(X_train,y_train)\n",
    "preds = xg_reg.predict(X_test)\n",
    "print('Accuracy Score : ' + str(accuracy_score(y_test,preds.round())))\n",
    "print('Precision Score : ' + str(precision_score(y_test,preds.round())))\n",
    "print('Recall Score : ' + str(recall_score(y_test,preds.round())))\n",
    "print('F1 Score : ' + str(f1_score(y_test,preds.round())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gonzams/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.7650918635170604\n",
      "Precision Score : 0.7567567567567568\n",
      "Recall Score : 0.676737160120846\n",
      "F1 Score : 0.7145135566188199\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestRegressor(random_state=13, n_estimators=5, max_depth=10)\n",
    "rf_model.fit(X_train, y_train)\n",
    "preds = rf_model.predict(X_test)\n",
    "\n",
    "print('Accuracy Score : ' + str(accuracy_score(y_test,preds.round())))\n",
    "print('Precision Score : ' + str(precision_score(y_test,preds.round())))\n",
    "print('Recall Score : ' + str(recall_score(y_test,preds.round())))\n",
    "print('F1 Score : ' + str(f1_score(y_test,preds.round())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gonzams/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.7664041994750657\n",
      "Precision Score : 0.8493150684931506\n",
      "Recall Score : 0.5619335347432024\n",
      "F1 Score : 0.6763636363636364\n"
     ]
    }
   ],
   "source": [
    "lgb_class = lgb.LGBMRegressor(learning_rate = 0.1,\n",
    "                max_depth = 10, alpha = 10, n_estimators = 5)\n",
    "lgb_class.fit(X_train, y_train)\n",
    "preds = lgb_class.predict(X_test)\n",
    "\n",
    "print('Accuracy Score : ' + str(accuracy_score(y_test,preds.round())))\n",
    "print('Precision Score : ' + str(precision_score(y_test,preds.round())))\n",
    "print('Recall Score : ' + str(recall_score(y_test,preds.round())))\n",
    "print('F1 Score : ' + str(f1_score(y_test,preds.round())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.4336822\ttotal: 751ms\tremaining: 3s\n",
      "1:\tlearn: 0.3964386\ttotal: 1.44s\tremaining: 2.16s\n",
      "2:\tlearn: 0.3712556\ttotal: 2.12s\tremaining: 1.41s\n",
      "3:\tlearn: 0.3503086\ttotal: 2.81s\tremaining: 704ms\n",
      "4:\tlearn: 0.3343915\ttotal: 3.49s\tremaining: 0us\n",
      "Accuracy Score : 0.7677165354330708\n",
      "Precision Score : 0.7673611111111112\n",
      "Recall Score : 0.6676737160120846\n",
      "F1 Score : 0.7140549273021002\n"
     ]
    }
   ],
   "source": [
    "catb = CatBoostRegressor(iterations=5, depth=10)\n",
    "catb.fit(X_train, y_train)\n",
    "preds = catb.predict(X_test)\n",
    "\n",
    "print('Accuracy Score : ' + str(accuracy_score(y_test,preds.round())))\n",
    "print('Precision Score : ' + str(precision_score(y_test,preds.round())))\n",
    "print('Recall Score : ' + str(recall_score(y_test,preds.round())))\n",
    "print('F1 Score : ' + str(f1_score(y_test,preds.round())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.7270341207349081\n",
      "Precision Score : 0.8219895287958116\n",
      "Recall Score : 0.4743202416918429\n",
      "F1 Score : 0.6015325670498084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gonzams/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingRegressor(n_estimators=5, learning_rate=0.1, \n",
    "                                max_features=2, max_depth = 10, random_state = 0)\n",
    "gb.fit(X_train, y_train)\n",
    "preds = gb.predict(X_test)\n",
    "\n",
    "print('Accuracy Score : ' + str(accuracy_score(y_test,preds.round())))\n",
    "print('Precision Score : ' + str(precision_score(y_test,preds.round())))\n",
    "print('Recall Score : ' + str(recall_score(y_test,preds.round())))\n",
    "print('F1 Score : ' + str(f1_score(y_test,preds.round())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gonzams/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_voting.py:406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.4347102\ttotal: 692ms\tremaining: 2.77s\n",
      "1:\tlearn: 0.3981527\ttotal: 1.4s\tremaining: 2.1s\n",
      "2:\tlearn: 0.3726670\ttotal: 2.11s\tremaining: 1.41s\n",
      "3:\tlearn: 0.3534779\ttotal: 2.79s\tremaining: 698ms\n",
      "4:\tlearn: 0.3399541\ttotal: 3.48s\tremaining: 0us\n",
      "Accuracy Score : 0.89501312335958\n",
      "Precision Score : 0.9372822299651568\n",
      "Recall Score : 0.8126888217522659\n",
      "F1 Score : 0.8705501618122976\n"
     ]
    }
   ],
   "source": [
    "eclf2 = VotingRegressor(estimators=[\n",
    "         ('xgb', xg_reg), ('rf', rf_model), ('catb', catb), ('gb', gb), ('lgbm',lgb_class)])\n",
    "\n",
    "eclf2 = eclf2.fit(X, y)\n",
    "preds = eclf2.predict(X_test)\n",
    "\n",
    "print('Accuracy Score : ' + str(accuracy_score(y_test,preds.round())))\n",
    "print('Precision Score : ' + str(precision_score(y_test,preds.round())))\n",
    "print('Recall Score : ' + str(recall_score(y_test,preds.round())))\n",
    "print('F1 Score : ' + str(f1_score(y_test,preds.round())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word2vec_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.556296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.674412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.725413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.758587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.598320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word2vec_score\n",
       "0        0.556296\n",
       "1        0.674412\n",
       "2        0.725413\n",
       "3        0.758587\n",
       "4        0.598320"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(eclf2.predict(X),columns=[\"word2vec_score\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = df.to_csv('../csv/solo_embedding_word2vec_train_lemm.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3263, 300)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_embeddings_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>0.534202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>0.583796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>0.527839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "      <td>0.548836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "      <td>0.726522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We're shaking...It's an earthquake</td>\n",
       "      <td>0.624894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>They'd probably still show more life than Arse...</td>\n",
       "      <td>0.237786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hey! How are you?</td>\n",
       "      <td>0.295767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What a nice hat?</td>\n",
       "      <td>0.281688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fuck off!</td>\n",
       "      <td>0.337627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash   \n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...   \n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...   \n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires   \n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan   \n",
       "5  12     NaN      NaN                 We're shaking...It's an earthquake   \n",
       "6  21     NaN      NaN  They'd probably still show more life than Arse...   \n",
       "7  22     NaN      NaN                                  Hey! How are you?   \n",
       "8  27     NaN      NaN                                   What a nice hat?   \n",
       "9  29     NaN      NaN                                          Fuck off!   \n",
       "\n",
       "     target  \n",
       "0  0.534202  \n",
       "1  0.583796  \n",
       "2  0.527839  \n",
       "3  0.548836  \n",
       "4  0.726522  \n",
       "5  0.624894  \n",
       "6  0.237786  \n",
       "7  0.295767  \n",
       "8  0.281688  \n",
       "9  0.337627  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['target'] = eclf2.predict(normalized_embeddings_test)\n",
    "test.drop(columns=['clean_text'], inplace=True)\n",
    "test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = test.to_csv('../csv/submission_word2vec_lemm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(eclf2.predict(normalized_embeddings_test),columns=[\"word2vec_score\"])\n",
    "df.head()\n",
    "final = df.to_csv('../csv/solo_embedding_word2vec_test_lemm.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
