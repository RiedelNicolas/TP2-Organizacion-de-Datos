{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se importan las bibliotecas necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se lee el .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7613 non-null   int64 \n",
      " 1   keyword   7552 non-null   object\n",
      " 2   location  5080 non-null   object\n",
      " 3   text      7613 non-null   object\n",
      " 4   target    7613 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('csv/train.csv')\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3263 entries, 0 to 3262\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        3263 non-null   int64 \n",
      " 1   keyword   3237 non-null   object\n",
      " 2   location  2158 non-null   object\n",
      " 3   text      3263 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 102.1+ KB\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('csv/test.csv')\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elaboración del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este modelo se utilizarán árboles de decisión para realizar las predicciones y se tendrán en cuenta los siguientes features extraídos del análisis exploratorio, los cuales fueron seleccionados por el grupo como aquellos que podrían resultan más interesantes:\n",
    "\n",
    "- Palabras con mayor y menor porcentaje de veracidad.\n",
    "- Pares de 2 palabras con mayor y menor porcentaje de veracidad.\n",
    "- Tweets que contienen @, ¿?, ¡! tienden a ser falsos.\n",
    "- Keywords con mayor y menor porcentaje de veracidad.\n",
    "- Locaciones más y menos veraces.\n",
    "- Longitud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparación del set de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parte inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>none_keyword</td>\n",
       "      <td>none_location</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>none_keyword</td>\n",
       "      <td>none_location</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>none_keyword</td>\n",
       "      <td>none_location</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>none_keyword</td>\n",
       "      <td>none_location</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>none_keyword</td>\n",
       "      <td>none_location</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       keyword       location  \\\n",
       "0   1  none_keyword  none_location   \n",
       "1   4  none_keyword  none_location   \n",
       "2   5  none_keyword  none_location   \n",
       "3   6  none_keyword  none_location   \n",
       "4   7  none_keyword  none_location   \n",
       "\n",
       "                                                text  target  \n",
       "0  Our Deeds are the Reason of this #earthquake M...       1  \n",
       "1             Forest fire near La Ronge Sask. Canada       1  \n",
       "2  All residents asked to 'shelter in place' are ...       1  \n",
       "3  13,000 people receive #wildfires evacuation or...       1  \n",
       "4  Just got sent this photo from Ruby #Alaska as ...       1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>none_keyword</td>\n",
       "      <td>none_location</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>none_keyword</td>\n",
       "      <td>none_location</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>none_keyword</td>\n",
       "      <td>none_location</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>none_keyword</td>\n",
       "      <td>none_location</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>none_keyword</td>\n",
       "      <td>none_location</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       keyword       location  \\\n",
       "0   0  none_keyword  none_location   \n",
       "1   2  none_keyword  none_location   \n",
       "2   3  none_keyword  none_location   \n",
       "3   9  none_keyword  none_location   \n",
       "4  11  none_keyword  none_location   \n",
       "\n",
       "                                                text  \n",
       "0                 Just happened a terrible car crash  \n",
       "1  Heard about #earthquake is different cities, s...  \n",
       "2  there is a forest fire at spot pond, geese are...  \n",
       "3           Apocalypse lighting. #Spokane #wildfires  \n",
       "4      Typhoon Soudelor kills 28 in China and Taiwan  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['location'].fillna(\"none_location\",inplace=True)\n",
    "train['keyword'].fillna(\"none_keyword\",inplace=True)\n",
    "display(train.head())\n",
    "test['location'].fillna(\"none_location\",inplace=True)\n",
    "test['keyword'].fillna(\"none_keyword\",inplace=True)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_repetitions = ((0.2/100)*len(train.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Devuelve una lista de tweets dejando solo caracteres alfanumericos\n",
    "def clean_text(df):\n",
    "    words = df['text'].str.split()\n",
    "    clean_words = []\n",
    "\n",
    "    for sentence in words:\n",
    "        clean_sentence = []\n",
    "        for word in sentence:\n",
    "            clean_word = re.sub('[^A-Za-z0-9]+','', word)\n",
    "            if(clean_word != ''):\n",
    "                clean_sentence.append(clean_word.lower())\n",
    "        clean_words.append(clean_sentence)\n",
    "    \n",
    "    return clean_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Devuelve una lista de tuplas de la forma (col, %veracidad)\n",
    "def groupby_veracity(df, col):\n",
    "    \n",
    "    veracity = []\n",
    "    aux = df.groupby(col).agg({'target':['sum','count']})\n",
    "    aux = aux[aux['target']['count']>min_repetitions]\n",
    "    aux['veracity'] = aux['target']['sum']/aux['target']['count']\n",
    "    aux.reset_index(inplace=True)\n",
    "    \n",
    "    for i in range(len(aux.index)):\n",
    "        veracity.append(tuple((aux[col][i],aux['veracity'][i])))\n",
    "    \n",
    "    return veracity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aux = train.copy()\n",
    "clean_tweets = clean_text(train_aux)\n",
    "train_aux['words'] = clean_tweets\n",
    "train_aux['clean_text'] = [' '.join(x) for x in clean_tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_pairs = []\n",
    "\n",
    "for sentence in train_aux['words']:\n",
    "    pairs = []\n",
    "    for i in range(len(sentence)-1):\n",
    "        pairs.append(sentence[i] + ' ' + sentence[i+1])\n",
    "    words_pairs.append(pairs)\n",
    "\n",
    "train_aux['pairs'] = words_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>words</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>pairs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>none_keyword</td>\n",
       "      <td>none_location</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>[our, deeds, are, the, reason, of, this, earth...</td>\n",
       "      <td>our deeds are the reason of this earthquake ma...</td>\n",
       "      <td>[our deeds, deeds are, are the, the reason, re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>none_keyword</td>\n",
       "      <td>none_location</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>[forest, fire, near, la, ronge, sask, canada]</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>[forest fire, fire near, near la, la ronge, ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>none_keyword</td>\n",
       "      <td>none_location</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[all, residents, asked, to, shelter, in, place...</td>\n",
       "      <td>all residents asked to shelter in place are be...</td>\n",
       "      <td>[all residents, residents asked, asked to, to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>none_keyword</td>\n",
       "      <td>none_location</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>[13000, people, receive, wildfires, evacuation...</td>\n",
       "      <td>13000 people receive wildfires evacuation orde...</td>\n",
       "      <td>[13000 people, people receive, receive wildfir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>none_keyword</td>\n",
       "      <td>none_location</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[just, got, sent, this, photo, from, ruby, ala...</td>\n",
       "      <td>just got sent this photo from ruby alaska as s...</td>\n",
       "      <td>[just got, got sent, sent this, this photo, ph...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       keyword       location  \\\n",
       "0   1  none_keyword  none_location   \n",
       "1   4  none_keyword  none_location   \n",
       "2   5  none_keyword  none_location   \n",
       "3   6  none_keyword  none_location   \n",
       "4   7  none_keyword  none_location   \n",
       "\n",
       "                                                text  target  \\\n",
       "0  Our Deeds are the Reason of this #earthquake M...       1   \n",
       "1             Forest fire near La Ronge Sask. Canada       1   \n",
       "2  All residents asked to 'shelter in place' are ...       1   \n",
       "3  13,000 people receive #wildfires evacuation or...       1   \n",
       "4  Just got sent this photo from Ruby #Alaska as ...       1   \n",
       "\n",
       "                                               words  \\\n",
       "0  [our, deeds, are, the, reason, of, this, earth...   \n",
       "1      [forest, fire, near, la, ronge, sask, canada]   \n",
       "2  [all, residents, asked, to, shelter, in, place...   \n",
       "3  [13000, people, receive, wildfires, evacuation...   \n",
       "4  [just, got, sent, this, photo, from, ruby, ala...   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0  our deeds are the reason of this earthquake ma...   \n",
       "1              forest fire near la ronge sask canada   \n",
       "2  all residents asked to shelter in place are be...   \n",
       "3  13000 people receive wildfires evacuation orde...   \n",
       "4  just got sent this photo from ruby alaska as s...   \n",
       "\n",
       "                                               pairs  \n",
       "0  [our deeds, deeds are, are the, the reason, re...  \n",
       "1  [forest fire, fire near, near la, la ronge, ro...  \n",
       "2  [all residents, residents asked, asked to, to ...  \n",
       "3  [13000 people, people receive, receive wildfir...  \n",
       "4  [just got, got sent, sent this, this photo, ph...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_aux.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = train_aux.copy()\n",
    "aux = aux.explode('words')\n",
    "veracity_words = groupby_veracity(aux, 'words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = train_aux.copy()\n",
    "aux = aux.explode('pairs')\n",
    "veracity_pairs = groupby_veracity(aux, 'pairs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "veracity_location = groupby_veracity(aux, 'location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "veracity_keyword = groupby_veracity(aux, 'keyword')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parte final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Devuelve una lista con la cantidad de palabras en 'words' que aparecen en cada elemento de 'texts'\n",
    "def count_text_ocurrences(texts, words):\n",
    "    ocurrences = []\n",
    "    for text in texts:\n",
    "        count = 0\n",
    "        for word in words:\n",
    "            if word in text:\n",
    "                count = count+1\n",
    "        ocurrences.append(count)\n",
    "    return ocurrences\n",
    "\n",
    "#Devuelve una lista binaria que indica si cada elemento de 'searched' aparece en 'series' o no\n",
    "def count_ocurrences(searched, series):\n",
    "    xd = ' '.join(series)\n",
    "    ocurrences = []\n",
    "    for element in searched:\n",
    "        count = 0\n",
    "        if element in xd:\n",
    "            count = count+1\n",
    "        ocurrences.append(count)\n",
    "    return ocurrences\n",
    "\n",
    "#Devuelve una lista binaria que indica si cada elemento de 'texts' contiene o no los chars recibidos\n",
    "def contains_char(texts, char1, char2=''):\n",
    "    ocurrences = []\n",
    "    for text in texts:\n",
    "        count = 0\n",
    "        if char1 in text:\n",
    "            count = 1\n",
    "        if (count==0)&(char2!=''):\n",
    "            if char2 in text:\n",
    "                count = 1\n",
    "        ocurrences.append(count)\n",
    "    return ocurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrega 2 columnas al df las cuales indican el número de palabras con mayor \n",
    "# y menor % de veracidad contiene cada tweet\n",
    "def relevant_words_occurrences(df, top_limit, low_limit):\n",
    "    \n",
    "    top_words = [x[0] for x in veracity_words if x[1]>top_limit]\n",
    "    worst_words = [x[0] for x in veracity_words if x[1]<low_limit]\n",
    "\n",
    "    df['top_words'] = count_text_ocurrences(df['clean_text'], top_words)\n",
    "    df['worst_words'] = count_text_ocurrences(df['clean_text'], worst_words)\n",
    "    \n",
    "    filtered_data.update([('top_words',top_words),('worst_words',worst_words)]) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrega 2 columnas al df las cuales indican el número de pares de palabras con mayor \n",
    "# y menor % de veracidad contiene cada tweet\n",
    "def relevant_words_pairs_occurrences(df,top_limit, low_limit):\n",
    "    \n",
    "    top_words_pairs = [x[0] for x in veracity_pairs if x[1]>top_limit]\n",
    "    worst_words_pairs = [x[0] for x in veracity_pairs if x[1]<low_limit]\n",
    "        \n",
    "    df['top_words_pairs'] = count_text_ocurrences(df['clean_text'], top_words_pairs)\n",
    "    df['worst_words_pairs'] = count_text_ocurrences(df['clean_text'], worst_words_pairs)\n",
    "    \n",
    "    filtered_data.update([('top_words_pairs',top_words_pairs),('worst_words_pairs',worst_words_pairs)]) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrega 2 columnas binarias al df las cuales indican si el tweet posee un keyword \n",
    "# con un alto o un bajo % de veracidad\n",
    "def relevant_keywords_occurrences(df, top_limit, low_limit):\n",
    "    \n",
    "    top_keywords = [x[0] for x in veracity_keyword if x[1]>top_limit]\n",
    "    worst_keywords = [x[0] for x in veracity_keyword if x[1]<low_limit]\n",
    "\n",
    "    df['top_keywords'] = count_ocurrences(df['keyword'], top_keywords)\n",
    "    df['worst_keywords'] = count_ocurrences(df['keyword'], worst_keywords)\n",
    "    \n",
    "    filtered_data.update([('top_keywords',top_keywords),('worst_keywords',worst_keywords)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrega 2 columnas binarias al df las cuales indican si el tweet proviene de una locacion \n",
    "# con un alto o un bajo % de veracidad\n",
    "\n",
    "def relevant_location_occurrences(df, top_limit, low_limit):\n",
    "    \n",
    "    top_locations = [x[0] for x in veracity_location if x[1]>top_limit]\n",
    "    worst_locations = [x[0] for x in veracity_location if x[1]<low_limit]\n",
    "    \n",
    "    df['top_locations'] = count_ocurrences(df['location'], top_locations)\n",
    "    df['worst_locations'] = count_ocurrences(df['location'], worst_locations)\n",
    "    \n",
    "    filtered_data.update([('top_locations',top_locations),('worst_locations',worst_locations)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrega 3 columnas binarias al df las cuales indican si el tweet contiene @, (¡,!) y (¿,?) \n",
    "def relevant_chars_ocurrences(df):\n",
    "    \n",
    "    df['arroba'] = contains_char(df['text'],'@')\n",
    "    df['signos_interrogacion'] = contains_char(df['text'],'?', '¿')\n",
    "    df['signos_exclamacion'] = contains_char(df['text'],'!','¡')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrega 2 columnas al df las cuales indican la longitud en palabras y caracteres de cada tweet\n",
    "def length_count(df):\n",
    "    \n",
    "    aux = []\n",
    "    words = df['text'].str.split()\n",
    "    \n",
    "    for i in words:\n",
    "        aux.append(len(i))\n",
    "\n",
    "    df['long(char)'] = df['text'].str.len()\n",
    "    df['long(word)'] = aux\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Devuelve un dataframe con todos los features considerados para el modelo\n",
    "def prepare_training_set(df):\n",
    "    \n",
    "    df['clean_text'] = [' '.join(x) for x in clean_tweets]\n",
    "    filtered_data.clear()\n",
    "    relevant_words_occurrences(df, 0.9, 0.1)\n",
    "    relevant_words_pairs_occurrences(df, 0.9, 0.1)\n",
    "    relevant_keywords_occurrences(df, 0.9, 0.1)\n",
    "    relevant_location_occurrences(df, 0.9, 0.1)\n",
    "    relevant_chars_ocurrences(df)\n",
    "    length_count(df)\n",
    "    \n",
    "    df = df.drop(columns=['keyword','location','text','clean_text'])\n",
    "    df = df.set_index('id')\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Devuelve un dataframe con todos los features considerados para el modelo\n",
    "def prepare_test_set(df):\n",
    "    \n",
    "    clean_tweets = clean_text(df)\n",
    "    df['words'] = clean_tweets\n",
    "    df['clean_text'] = [' '.join(x) for x in clean_tweets]\n",
    "    \n",
    "    df['top_words'] = count_text_ocurrences(df['clean_text'], filtered_data['top_words'])\n",
    "    df['worst_words'] = count_text_ocurrences(df['clean_text'], filtered_data['worst_words'])\n",
    "    df['top_words_pairs'] = count_text_ocurrences(df['clean_text'], filtered_data['top_words_pairs'])\n",
    "    df['worst_words_pairs'] = count_text_ocurrences(df['clean_text'], filtered_data['worst_words_pairs'])\n",
    "    df['top_keywords'] = count_ocurrences(df['keyword'], filtered_data['top_keywords'])\n",
    "    df['worst_keywords'] = count_ocurrences(df['keyword'], filtered_data['worst_keywords'])\n",
    "    df['top_locations'] = count_ocurrences(df['location'], filtered_data['top_locations'])\n",
    "    df['worst_locations'] = count_ocurrences(df['location'], filtered_data['worst_locations'])\n",
    "    relevant_chars_ocurrences(df)\n",
    "    length_count(df)\n",
    "    \n",
    "    df = df.drop(columns=['keyword','location','text','words','clean_text'])\n",
    "    df = df.set_index('id')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>top_words</th>\n",
       "      <th>worst_words</th>\n",
       "      <th>top_words_pairs</th>\n",
       "      <th>worst_words_pairs</th>\n",
       "      <th>top_keywords</th>\n",
       "      <th>worst_keywords</th>\n",
       "      <th>top_locations</th>\n",
       "      <th>worst_locations</th>\n",
       "      <th>arroba</th>\n",
       "      <th>signos_interrogacion</th>\n",
       "      <th>signos_exclamacion</th>\n",
       "      <th>long(char)</th>\n",
       "      <th>long(word)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    target  top_words  worst_words  top_words_pairs  worst_words_pairs  \\\n",
       "id                                                                       \n",
       "1        1          0            0                0                  0   \n",
       "4        1          0            0                0                  0   \n",
       "5        1          1            0                0                  0   \n",
       "6        1          2            0                0                  0   \n",
       "7        1          1            0                0                  0   \n",
       "\n",
       "    top_keywords  worst_keywords  top_locations  worst_locations  arroba  \\\n",
       "id                                                                         \n",
       "1              1               0              0                0       0   \n",
       "4              1               0              0                0       0   \n",
       "5              1               0              0                0       0   \n",
       "6              1               0              0                0       0   \n",
       "7              1               0              0                0       0   \n",
       "\n",
       "    signos_interrogacion  signos_exclamacion  long(char)  long(word)  \n",
       "id                                                                    \n",
       "1                      0                   0          69          13  \n",
       "4                      0                   0          38           7  \n",
       "5                      0                   0         133          22  \n",
       "6                      0                   0          65           8  \n",
       "7                      0                   0          88          16  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set = prepare_training_set(train.copy())\n",
    "training_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top_words</th>\n",
       "      <th>worst_words</th>\n",
       "      <th>top_words_pairs</th>\n",
       "      <th>worst_words_pairs</th>\n",
       "      <th>top_keywords</th>\n",
       "      <th>worst_keywords</th>\n",
       "      <th>top_locations</th>\n",
       "      <th>worst_locations</th>\n",
       "      <th>arroba</th>\n",
       "      <th>signos_interrogacion</th>\n",
       "      <th>signos_exclamacion</th>\n",
       "      <th>long(char)</th>\n",
       "      <th>long(word)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    top_words  worst_words  top_words_pairs  worst_words_pairs  top_keywords  \\\n",
       "id                                                                             \n",
       "0           0            0                0                  0             1   \n",
       "2           0            0                0                  0             1   \n",
       "3           0            0                0                  0             1   \n",
       "9           1            0                0                  0             1   \n",
       "11          3            0                1                  0             1   \n",
       "\n",
       "    worst_keywords  top_locations  worst_locations  arroba  \\\n",
       "id                                                           \n",
       "0                0              0                0       0   \n",
       "2                0              0                0       0   \n",
       "3                0              0                0       0   \n",
       "9                0              0                0       0   \n",
       "11               0              0                0       0   \n",
       "\n",
       "    signos_interrogacion  signos_exclamacion  long(char)  long(word)  \n",
       "id                                                                    \n",
       "0                      0                   0          34           6  \n",
       "2                      0                   0          64           9  \n",
       "3                      0                   0          96          19  \n",
       "9                      0                   0          40           4  \n",
       "11                     0                   0          45           8  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = prepare_test_set(test.copy())\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento del set de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = training_set.iloc[:,1:-1], training_set.iloc[:,0]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 20, alpha = 10, n_estimators = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(alpha=10, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=20,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=20, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='binary:logistic', random_state=0, reg_alpha=10,\n",
       "              reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.7690288713910761\n",
      "Precision Score : 0.8382978723404255\n",
      "Recall Score : 0.5880597014925373\n",
      "F1 Score : 0.6912280701754386\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy Score : ' + str(accuracy_score(y_test,preds)))\n",
    "print('Precision Score : ' + str(precision_score(y_test,preds)))\n",
    "print('Recall Score : ' + str(recall_score(y_test,preds)))\n",
    "print('F1 Score : ' + str(f1_score(y_test,preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(preds)\n",
    "# final = df.to_csv('csv/xgboost.csv')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#         'min_child_weight': [1, 5, 10],\n",
    "#         'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "#         'subsample': [0.6, 0.8, 1.0],\n",
    "#         'colsample_bytree': [0.2, 0.3, 0.4],\n",
    "#         'max_depth': [10, 15, 20]\n",
    "#         }\n",
    "# grid_acc = GridSearchCV(xg_reg, param_grid = params)\n",
    "# grid_acc.fit(X_train, y_train)\n",
    "# y_pred_acc = grid_acc.predict(X_test)\n",
    "\n",
    "# # New Model Evaluation metrics \n",
    "# print('Accuracy Score : ' + str(accuracy_score(y_test,y_pred_acc.round())))\n",
    "# print('Precision Score : ' + str(precision_score(y_test,y_pred_acc.round())))\n",
    "# print('Recall Score : ' + str(recall_score(y_test,y_pred_acc.round())))\n",
    "# print('F1 Score : ' + str(f1_score(y_test,y_pred_acc.round())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_model = RandomForestClassifier(random_state=13, n_estimators=80, max_depth=20)\n",
    "# rf_model.fit(X_train, y_train)\n",
    "# preds = rf_model.predict(X_test)\n",
    "\n",
    "# print('Accuracy Score : ' + str(accuracy_score(y_test,preds.round())))\n",
    "# print('Precision Score : ' + str(precision_score(y_test,preds.round())))\n",
    "# print('Recall Score : ' + str(recall_score(y_test,preds.round())))\n",
    "# print('F1 Score : ' + str(f1_score(y_test,preds.round())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(preds)\n",
    "# final = df.to_csv('csv/randomForest.csv')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rf_model.feature_importances_\n",
    "plt.figure(figsize=(17,9))\n",
    "plt.bar(X_train.columns, rf_model.feature_importances_)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importancia')\n",
    "plt.title('Importancia Features con RF')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgb_train = lgb.Dataset(X_train, y_train)\n",
    "# lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
    "\n",
    "# params = {\n",
    "#      'objective': 'regression',\n",
    "#      'metric': 'rmse',\n",
    "#      'num_leaves': 5,\n",
    "#      'learning_rate': 0.1,\n",
    "#      'feature_fraction': 0.9,\n",
    "#  }\n",
    "\n",
    "# params = {\n",
    "#      'objective': 'regression',\n",
    "#  }\n",
    "\n",
    "# gbm = lgb.train(params,\n",
    "#                  lgb_train,\n",
    "#                  num_boost_round=100,\n",
    "#                  valid_sets=lgb_eval,\n",
    "#                  early_stopping_rounds=10)\n",
    "\n",
    "# preds = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
    "# print('Accuracy Score : ' + str(accuracy_score(y_test,preds.round())))\n",
    "# print('Precision Score : ' + str(precision_score(y_test,preds.round())))\n",
    "# print('Recall Score : ' + str(recall_score(y_test,preds.round())))\n",
    "# print('F1 Score : ' + str(f1_score(y_test,preds.round())))\n",
    "# rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "# print(\"RMSE: %f\" % (rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(preds)\n",
    "# final = df.to_csv('csv/lightgbm.csv')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = CatBoostClassifier()\n",
    "# model.fit(X_train, y_train)\n",
    "# preds = model.predict(X_test)\n",
    "\n",
    "# print('Accuracy Score : ' + str(accuracy_score(y_test,preds.round())))\n",
    "# print('Precision Score : ' + str(precision_score(y_test,preds.round())))\n",
    "# print('Recall Score : ' + str(recall_score(y_test,preds.round())))\n",
    "# print('F1 Score : ' + str(f1_score(y_test,preds.round())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(preds)\n",
    "# final = df.to_csv('csv/catboost.csv')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LogisticRegression()\n",
    "# model.fit(X_train, y_train)\n",
    "# preds = model.predict(X_test)\n",
    "\n",
    "# print('Accuracy Score : ' + str(accuracy_score(y_test,preds.round())))\n",
    "# print('Precision Score : ' + str(precision_score(y_test,preds.round())))\n",
    "# print('Recall Score : ' + str(recall_score(y_test,preds.round())))\n",
    "# print('F1 Score : ' + str(f1_score(y_test,preds.round())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(preds)\n",
    "# final = df.to_csv('csv/logicRegression.csv')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xg_reg = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "#                 colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "#                 max_depth = 20, alpha = 10, n_estimators = 80)\n",
    "# rf_model = RandomForestClassifier(random_state=13, n_estimators=80, max_depth=20)\n",
    "\n",
    "# eclf2 = VotingClassifier(estimators=[\n",
    "#          ('xgb', xg_reg), ('rf', rf_model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eclf2 = eclf2.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = eclf2.predict(X_test)\n",
    "\n",
    "# print('Accuracy Score : ' + str(accuracy_score(y_test,preds.round())))\n",
    "# print('Precision Score : ' + str(precision_score(y_test,preds.round())))\n",
    "# print('Recall Score : ' + str(recall_score(y_test,preds.round())))\n",
    "# print('F1 Score : ' + str(f1_score(y_test,preds.round())))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
