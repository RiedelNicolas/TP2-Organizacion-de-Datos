{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformers&Bert.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdb8DxJbCUsF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "200bd556-0fd6-4328-9e33-b2043653b9ec"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc1 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8.1rc1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5tOzcSB_Kyy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "f0ab05e3-4cdf-4f57-c3b4-63903af147f1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_Y9B5r8cJ-h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "a1fddc31-9356-4362-ac2a-78501abefe87"
      },
      "source": [
        "pip install glue"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting glue\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/59/e645bf02685eff415fb5c2ceda9693b26ebb0340b1c43c145a5ff323b2fe/glue-0.13.tar.gz (295kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from glue) (7.0.0)\n",
            "Collecting Jinja2<2.10,>=2.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/73/10c45b82a88ed6b7751bd40da31eeefd7b362e07b56a99aa6e56655a0794/Jinja2-2.9.6-py2.py3-none-any.whl (340kB)\n",
            "\u001b[K     |████████████████████████████████| 348kB 10.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2<2.10,>=2.7->glue) (1.1.1)\n",
            "Building wheels for collected packages: glue\n",
            "  Building wheel for glue (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for glue: filename=glue-0.13-cp36-none-any.whl size=28282 sha256=551196f0a50f1a9f09ac042ea4437e8b993decb7a3c4b1021abc9a1c78fb15bc\n",
            "  Stored in directory: /root/.cache/pip/wheels/69/09/09/e213b576abd91be00f007915e24c41aa5c897e4e48a4a28158\n",
            "Successfully built glue\n",
            "\u001b[31mERROR: flask 1.1.2 has requirement Jinja2>=2.10.1, but you'll have jinja2 2.9.6 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: Jinja2, glue\n",
            "  Found existing installation: Jinja2 2.11.2\n",
            "    Uninstalling Jinja2-2.11.2:\n",
            "      Successfully uninstalled Jinja2-2.11.2\n",
            "Successfully installed Jinja2-2.9.6 glue-0.13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NGNEmT3C3Iz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import string\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tokenizers import BertWordPieceTokenizer\n",
        "from transformers import BertTokenizer, TFBertModel, BertConfig, TFBertForSequenceClassification\n",
        "from transformers import glue_convert_examples_to_features\n",
        "import pandas as pd\n",
        "import tensorflow_datasets"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Re96-3Fk_TJH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv('/content/drive/My Drive/nlp-getting-started/train.csv')\n",
        "test = pd.read_csv('/content/drive/My Drive/nlp-getting-started/test.csv')\n",
        "submission = pd.read_csv(\"/content/drive/My Drive/nlp-getting-started/sample_submission.csv\")"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZmIaAi2_b_P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ids_with_target_error = [328,443,513,2619,3640,3900,4342,5781,6552,6554,6570,6701,6702,6729,6861,7226]\n",
        "train.loc[train['id'].isin(ids_with_target_error),'target'] = 0"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HALHMG8A_cB1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "62849945-85f1-4a8b-c2c0-03f85b1c1c4d"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "model = TFBertForSequenceClassification.from_pretrained('bert-base-cased')\n",
        "data = tensorflow_datasets.load('glue/mrpc')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:transformers.modeling_tf_utils:Some weights of the model checkpoint at bert-base-cased were not used when initializing TFBertForSequenceClassification: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "WARNING:transformers.modeling_tf_utils:Some weights of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier', 'dropout_189']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "INFO:absl:Overwrite dataset info from restored data version.\n",
            "INFO:absl:Reusing dataset glue (/root/tensorflow_datasets/glue/mrpc/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split None, from /root/tensorflow_datasets/glue/mrpc/1.0.0\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Te91oMvCQIR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = glue_convert_examples_to_features(data['train'], tokenizer, max_length = 128, task = 'mrpc')\n",
        "valid_dataset = glue_convert_examples_to_features(data['validation'], tokenizer, max_length = 128, task = 'mrpc')\n",
        "train_dataset = train_dataset.shuffle(100).batch(32).repeat(2)\n",
        "valid_dataset = valid_dataset.batch(64)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2YX5uC1_cGS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate = 3e-5, epsilon = 1e-8, clipnorm =1.0)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True)\n",
        "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
        "model.compile(optimizer = optimizer, loss = loss, metrics = [metric])"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rol_yvc_eRUX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(train_dataset, epochs = 2, steps_per_epoch = 115, validation_data = valid_dataset, validation_steps = 7)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}